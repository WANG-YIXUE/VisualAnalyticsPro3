#check what object types we have
class(data)
class(Edinburgh_map)
#Check what are the column names of the dataframe, and of the spatial points dataframe?
names(data)
names(Edinburgh_map)
#check how many rows do each of the datasets contain?
nrow(data)
nrow(Edinburgh_map)
#check the coordinate system of the spatial polygons data frame
proj4string(Edinburgh_map)
#plot the spatial polygons data frame
plot(Edinburgh_map)
#convert the object into latitude and longitude for easier use with ggmap
Edinburgh_map <- spTransform(Edinburgh_map, CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs"))
#convert spatial polygon to dataframe including columns of spatial information
Edinburgh_fort <- fortify(Edinburgh_map, region= "DataZone")
#merge the new dataframe with the Edinburgh census data using their shared column (ID)
Edinburgh_fort <- merge(Edinburgh_fort, data, by="id")
View(Edinburgh_fort)
View(Edinburgh_fort)
#convert spatial polygon to dataframe including columns of spatial information
Edinburgh_fort <- fortify(Edinburgh_map, region= "DataZone")
#merge the new dataframe with the Edinburgh census data using their shared column (ID)
Edinburgh_fort <- merge(Edinburgh_fort, data, by="id")
View(Edinburgh_fort)
#merge the new dataframe with the Edinburgh census data using their shared column (ID)
Edinburgh_fort <- merge(Edinburgh_fort, data, by="id")
#create a plot of Income
ggplot(data=Edinburgh_fort, aes(x=long, y=lat, fill=Income, group=group)) +
scale_fill_viridis(name = "Income Rate")+
geom_polygon(colour="Gray")+
theme_void() +
theme(legend.position = "bottom") +
coord_equal()
#create a plot of Income
ggplot(data=Edinburgh_fort, aes(x=long, y=lat, fill=IncNumDep, group=group)) +
scale_fill_viridis(name = "Income Rate")+
geom_polygon(colour="Gray")+
theme_void() +
theme(legend.position = "bottom") +
coord_equal()
#read in deprivation data for the Edinburgh area
data <- read.table(file="assignment3.csv", sep=",", header=TRUE)
#convert spatial polygon to dataframe including columns of spatial information
Edinburgh_fort <- fortify(Edinburgh_map, region= "DataZone")
#merge the new dataframe with the Edinburgh census data using their shared column (ID)
Edinburgh_fort <- merge(Edinburgh_fort, data, by="id")
#merge the new dataframe with the Edinburgh census data using their shared column (ID)
Edinburgh_fort <- merge(Edinburgh_fort, data, by.x="DataZone", by.y="id")
View(Edinburgh_fort)
#merge the new dataframe with the Edinburgh census data using their shared column (ID)
Edinburgh_fort <- merge(Edinburgh_fort, data, by="DataZone")
#read in deprivation data for the Edinburgh area
data <- read.table(file="assignment3.csv", sep=",", header=TRUE)
View(data)
#merge the new dataframe with the Edinburgh census data using their shared column (ID)
Edinburgh_fort <- merge(Edinburgh_fort, data, by="DataZone")
View(data)
View(Edinburgh_fort)
#merge the new dataframe with the Edinburgh census data using their shared column (ID)
Edinburgh_fort <- merge(Edinburgh_fort, data, by="id")
#merge the new dataframe with the Edinburgh census data using their shared column (ID)
Edinburgh_fort <- merge(Edinburgh_fort, data, by="DataZone")
View(Edinburgh_fort)
#read in deprivation data for the Edinburgh area
data <- read.table(file="assignment3.csv", sep=",", header=TRUE)
View(data)
#convert spatial polygon to dataframe including columns of spatial information
Edinburgh_fort <- fortify(Edinburgh_map, region= "DataZone")
#install.packages('kohonen')
library(kohonen)
library(ggplot2)
library(rgdal)
library(gridExtra)
library(grid)
library(viridis)
library(dplyr)
#convert spatial polygon to dataframe including columns of spatial information
Edinburgh_fort <- fortify(Edinburgh_map, region= "DataZone")
#merge the new dataframe with the Edinburgh census data using their shared column
Edinburgh_fort <- merge(Edinburgh_fort, data, by="DataZone")
#merge the new dataframe with the Edinburgh census data using their shared column
Edinburgh_fort <- merge(Edinburgh_fort, data, by="id")
#merge the new dataframe with the Edinburgh census data using their shared column
Edinburgh_fort <- merge(Edinburgh_fort, data, by.x="id", by.y="DataZone")
#read in the boundary data for the Edinburgh area, already matched up by row with the census data
Edinburgh_map <- readOGR("AssessmentData/SG_SIMD_2016_EDINBURGH.shp", stringsAsFactors = FALSE)
#check what object types we have
class(data)
class(Edinburgh_map)
#Check what are the column names of the dataframe, and of the spatial points dataframe?
names(data)
names(Edinburgh_map)
#check how many rows do each of the datasets contain?
nrow(data)
nrow(Edinburgh_map)
#check the coordinate system of the spatial polygons data frame
proj4string(Edinburgh_map)
#plot the spatial polygons data frame
plot(Edinburgh_map)
#convert the object into latitude and longitude for easier use with ggmap
Edinburgh_map <- spTransform(Edinburgh_map, CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs"))
#convert spatial polygon to dataframe including columns of spatial information
Edinburgh_fort <- fortify(Edinburgh_map, region= "DataZone")
#merge the new dataframe with the Edinburgh census data using their shared column
Edinburgh_fort <- merge(Edinburgh_fort, data, by.x="id", by.y="DataZone")
#create a plot of Income
ggplot(data=Edinburgh_fort, aes(x=long, y=lat, fill=IncNumDep, group=group)) +
scale_fill_viridis(name = "Income Rate")+
geom_polygon(colour="Gray")+
theme_void() +
theme(legend.position = "bottom") +
coord_equal()
#create a plot of Income
ggplot(data=Edinburgh_fort, aes(x=long, y=lat, fill=IncNumDep, group=group)) +
scale_fill_viridis(name = "Income Deprivation")+
geom_polygon(colour="Gray")+
theme_void() +
theme(legend.position = "bottom") +
coord_equal()
#create a plot of Employment
ggplot(data=Edinburgh_fort, aes(x=long, y=lat, fill=EmpNumDep, group=group)) +
scale_fill_viridis(name = "Employment Deprivation")+
geom_polygon(colour="Black")+
theme_void() +
theme(legend.position = "bottom") +
coord_equal()
#create a plot of HouseNumOC (Number of people in households that are overcrowded )
ggplot(data=Edinburgh_fort, aes(x=long, y=lat, fill=HouseNumOC, group=group)) +
scale_fill_viridis(name = "Overcrowded Level")+
geom_polygon(colour="Black")+
theme_void() +
theme(legend.position = "bottom") +
coord_equal()
#create a plot of EduNoQuals(Working age people with no qualifications)
ggplot(data=Edinburgh_fort, aes(x=long, y=lat, fill=EduNoQuals, group=group)) +
scale_fill_viridis(name = "Education Deprivation")+
geom_polygon(colour="Gray")+
theme_void() +
theme(legend.position = "bottom") +
coord_equal()
#choose the variables with which to train the SOM by subsetting the dataframe called data
data_train <- select(data, IncNumDep, EmpNumDep, HouseNumOC, EduNoQuals)
#convert to a matrix
data_train_matrix <- as.matrix(data_train)
#keep the column names of data_train as names in our new matrix
names(data_train_matrix) <- names(data_train)
#define the size and topology of the som grid
som_grid <- somgrid(xdim = 15, ydim=15, topo="hexagonal")
# Train the SOM model!
som_model <- som(data_train_matrix,
grid=som_grid,
rlen=500,
alpha=c(0.1,0.01),
keep.data = TRUE )
# Plot of the training progress - how the node distances have stabilised over time.
#mean distance to closes codebook vector during training
plot(som_model, type = "changes")
#counts within nodes
plot(som_model, type = "counts", main="Node Counts", palette.name=coolBlueHotRed)
## load custom palette, created by Shane Lynn
source('coolBlueHotRed.R')
#counts within nodes
plot(som_model, type = "counts", main="Node Counts", palette.name=coolBlueHotRed)
#map quality
plot(som_model, type = "quality", main="Node Quality/Distance", palette.name=coolBlueHotRed)
#neighbour distances
plot(som_model, type="dist.neighbours", main = "SOM neighbour distances", palette.name=grey.colors)
#code spread
plot(som_model, type = "codes")
# Plot the heatmap for a variable at scaled / normalised values
var <- 1 #define the variable to plot
plot(som_model, type = "property", property = getCodes(som_model)[,var], main=colnames(getCodes(som_model))[var], palette.name=coolBlueHotRed)
var <- 2
plot(som_model, type = "property", property = getCodes(som_model)[,var], main=colnames(getCodes(som_model))[var], palette.name=coolBlueHotRed)
var <- 3
plot(som_model, type = "property", property = getCodes(som_model)[,var], main=colnames(getCodes(som_model))[var], palette.name=coolBlueHotRed)
var <- 4
plot(som_model, type = "property", property = getCodes(som_model)[,var], main=colnames(getCodes(som_model))[var], palette.name=coolBlueHotRed)
# show the WCSS metric for kmeans for different clustering sizes.
# Can be used as a "rough" indicator of the ideal number of clusters
mydata <- getCodes(som_model)
wss <- (nrow(mydata)-1)*sum(apply(mydata,2,var))
for (i in 2:15) wss[i] <- sum(kmeans(mydata,
centers=i)$withinss)
plot(1:15, wss, type="b", xlab="Number of Clusters",
ylab="Within groups sum of squares", main="Within cluster sum of squares (WCSS)")
# Form clusters on grid
## use hierarchical clustering to cluster the codebook vectors
som_cluster <- cutree(hclust(dist(getCodes(som_model))), 5)
# Colour palette definition
pretty_palette <- c("#D9D7F1", '#FFFDDE', '#2ca02c', '#E7FBBE', '#FFCBCB')
#show the same plot with the codes instead of just colours
plot(som_model, type="codes", bgcol = pretty_palette[som_cluster], main = "Clusters")
add.cluster.boundaries(som_model, som_cluster)
#create a label set for our SOM - a random subset of EDNAME
#extract the the names of areas in Edinburgh
geog_names <- Edinburgh_map@data$Intermedia
#most EDNAME values are repeated, so we'll remove duplicates, just to get an idea of the spread across Edinburgh
geog_names[duplicated(geog_names)] <- NA
#find the index of the names which are not NA
naset <- which(!is.na(geog_names))
#make all but 10 of the placenames in our data NA
naset <- sample(naset, length(naset)-10)
geog_names[naset] <- NA
# Replot our data with labels=geog_names
plot(som_model, type="mapping", bgcol = pretty_palette[som_cluster], main = "Clusters", labels=geog_names)
add.cluster.boundaries(som_model, som_cluster)
# Another Replot our data with labels=geog_names
plot(som_model, type="mapping", bgcol = cbPalette[som_cluster], main = "Clusters", labels=geog_names)
add.cluster.boundaries(som_model, som_cluster)
#create dataframe of the small area id and of the cluster unit
cluster_details <- data.frame(id=data$id, cluster=som_cluster[som_model$unit.classif])
# Replot our data with labels=geog_names
plot(som_model, type="mapping", bgcol = pretty_palette[som_cluster], main = "Clusters", labels=geog_names)
add.cluster.boundaries(som_model, som_cluster)
#create dataframe of the small area id and of the cluster unit
cluster_details <- data.frame(id=data$id, cluster=som_cluster[som_model$unit.classif])
#create dataframe of the small area id and of the cluster unit
cluster_details <- data.frame(id=data$DataZone, cluster=som_cluster[som_model$unit.classif])
#we can just merge our cluster details onto the fortified spatial polygon dataframe we created earlier
mappoints <- merge(Edinburgh_fort, cluster_details, by="id")
pretty_palette1 <- c("#69779B", '#9692AF', '#ACDBDF', '#D7EAEA', '#41AAA8')
# Finally map the areas and colour by cluster
ggplot(data=mappoints, aes(x=long, y=lat, group=group, fill=factor(cluster))) +
geom_polygon(colour="black")  +
coord_equal() +
scale_fill_manual(values = pretty_palette1)
#read in the boundary data for the Edinburgh area, already matched up by row with the census data
Edinburgh_map <- readOGR("SG_SIMD_2016_EDINBURGH.shp", stringsAsFactors = FALSE)
#Setting up a working directory
setwd("M:/VA/assignment3")
#install.packages('kohonen')
library(kohonen)
library(ggplot2)
library(rgdal)
library(gridExtra)
library(grid)
library(viridis)
library(dplyr)
#read in deprivation data for the Edinburgh area
data <- read.table(file="assignment3.csv", sep=",", header=TRUE)
#read in the boundary data for the Edinburgh area, already matched up by row with the census data
Edinburgh_map <- readOGR("SG_SIMD_2016_EDINBURGH.shp", stringsAsFactors = FALSE)
#check what object types we have
class(data)
class(Edinburgh_map)
#Check what are the column names of the dataframe, and of the spatial points dataframe?
names(data)
names(Edinburgh_map)
#check how many rows do each of the datasets contain?
nrow(data)
nrow(Edinburgh_map)
#check the coordinate system of the spatial polygons data frame
proj4string(Edinburgh_map)
#plot the spatial polygons data frame
plot(Edinburgh_map)
#convert the object into latitude and longitude for easier use with ggmap
Edinburgh_map <- spTransform(Edinburgh_map, CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs"))
#convert spatial polygon to dataframe including columns of spatial information
Edinburgh_fort <- fortify(Edinburgh_map, region= "DataZone")
#merge the new dataframe with the Edinburgh census data using their shared column
Edinburgh_fort <- merge(Edinburgh_fort, data, by.x="id", by.y="DataZone")
#create a plot of Income (Number of people who are income deprived)
ggplot(data=Edinburgh_fort, aes(x=long, y=lat, fill=IncNumDep, group=group)) +
scale_fill_viridis(name = "Income Deprivation")+
geom_polygon(colour="Gray")+
theme_void() +
theme(legend.position = "bottom") +
coord_equal()
#create a plot of Employment (Number of people who areemployment deprived)
ggplot(data=Edinburgh_fort, aes(x=long, y=lat, fill=EmpNumDep, group=group)) +
scale_fill_viridis(name = "Employment Deprivation")+
geom_polygon(colour="Black")+
theme_void() +
theme(legend.position = "bottom") +
coord_equal()
#create a plot of HouseNumOC (Number of people in households that are overcrowded )
ggplot(data=Edinburgh_fort, aes(x=long, y=lat, fill=HouseNumOC, group=group)) +
scale_fill_viridis(name = "Overcrowded Level")+
geom_polygon(colour="Black")+
theme_void() +
theme(legend.position = "bottom") +
coord_equal()
#create a plot of EduNoQuals(Working age people with no qualifications)
ggplot(data=Edinburgh_fort, aes(x=long, y=lat, fill=EduNoQuals, group=group)) +
scale_fill_viridis(name = "Education Deprivation")+
geom_polygon(colour="Gray")+
theme_void() +
theme(legend.position = "bottom") +
coord_equal()
#choose the variables with which to train the SOM by subsetting the dataframe called data
data_train <- select(data, IncNumDep, EmpNumDep, HouseNumOC, EduNoQuals)
#convert to a matrix
data_train_matrix <- as.matrix(data_train)
#keep the column names of data_train as names in our new matrix
names(data_train_matrix) <- names(data_train)
#define the size and topology of the som grid
som_grid <- somgrid(xdim = 15, ydim=15, topo="hexagonal")
# Train the SOM model!
som_model <- som(data_train_matrix,
grid=som_grid,
rlen=500,
alpha=c(0.1,0.01),
keep.data = TRUE )
# Plot of the training progress - how the node distances have stabilised over time.
#mean distance to closes codebook vector during training
plot(som_model, type = "changes")
## load custom palette, created by Shane Lynn
source('coolBlueHotRed.R')
#counts within nodes
plot(som_model, type = "counts", main="Node Counts", palette.name=coolBlueHotRed)
#map quality
plot(som_model, type = "quality", main="Node Quality/Distance", palette.name=coolBlueHotRed)
#neighbour distances
plot(som_model, type="dist.neighbours", main = "SOM neighbour distances", palette.name=grey.colors)
#code spread
plot(som_model, type = "codes")
# Plot the heatmap for a variable at scaled / normalised values
var <- 1 #define the variable to plot
plot(som_model, type = "property", property = getCodes(som_model)[,var], main=colnames(getCodes(som_model))[var], palette.name=coolBlueHotRed)
var <- 2
plot(som_model, type = "property", property = getCodes(som_model)[,var], main=colnames(getCodes(som_model))[var], palette.name=coolBlueHotRed)
var <- 3
plot(som_model, type = "property", property = getCodes(som_model)[,var], main=colnames(getCodes(som_model))[var], palette.name=coolBlueHotRed)
var <- 4
plot(som_model, type = "property", property = getCodes(som_model)[,var], main=colnames(getCodes(som_model))[var], palette.name=coolBlueHotRed)
# show the WCSS metric for kmeans for different clustering sizes.
# Can be used as a "rough" indicator of the ideal number of clusters
mydata <- getCodes(som_model)
wss <- (nrow(mydata)-1)*sum(apply(mydata,2,var))
for (i in 2:15) wss[i] <- sum(kmeans(mydata,
centers=i)$withinss)
plot(1:15, wss, type="b", xlab="Number of Clusters",
ylab="Within groups sum of squares", main="Within cluster sum of squares (WCSS)")
# Form clusters on grid
## use hierarchical clustering to cluster the codebook vectors
som_cluster <- cutree(hclust(dist(getCodes(som_model))), 5)
# Colour palette definition
pretty_palette <- c("#D9D7F1", '#FFFDDE', '#2ca02c', '#E7FBBE', '#FFCBCB')
#show the same plot with the codes instead of just colours
plot(som_model, type="codes", bgcol = pretty_palette[som_cluster], main = "Clusters")
add.cluster.boundaries(som_model, som_cluster)
#create a label set for our SOM - a random subset of EDNAME
#extract the the names of areas in Edinburgh
geog_names <- Edinburgh_map@data$Intermedia
#most EDNAME values are repeated, so we'll remove duplicates, just to get an idea of the spread across Edinburgh
geog_names[duplicated(geog_names)] <- NA
#find the index of the names which are not NA
naset <- which(!is.na(geog_names))
#make all but 10 of the placenames in our data NA
naset <- sample(naset, length(naset)-10)
geog_names[naset] <- NA
# Replot our data with labels=geog_names
plot(som_model, type="mapping", bgcol = pretty_palette[som_cluster], main = "Clusters", labels=geog_names)
add.cluster.boundaries(som_model, som_cluster)
#create dataframe of the small area id and of the cluster unit
cluster_details <- data.frame(id=data$DataZone, cluster=som_cluster[som_model$unit.classif])
#we can just merge our cluster details onto the fortified spatial polygon dataframe we created earlier
mappoints <- merge(Edinburgh_fort, cluster_details, by="id")
pretty_palette1 <- c("#69779B", '#9692AF', '#ACDBDF', '#D7EAEA', '#41AAA8')
# Finally map the areas and colour by cluster
ggplot(data=mappoints, aes(x=long, y=lat, group=group, fill=factor(cluster))) +
geom_polygon(colour="black")  +
coord_equal() +
scale_fill_manual(values = pretty_palette1)
#Setting up a working directory
setwd("M:/VA/assignment3")
#install.packages('kohonen')
library(kohonen)
library(ggplot2)
library(rgdal)
library(gridExtra)
library(grid)
library(viridis)
library(dplyr)
#read in deprivation data for the Edinburgh area
data <- read.table(file="assignment3.csv", sep=",", header=TRUE)
#read in the boundary data for the Edinburgh area, already matched up by row with the census data
Edinburgh_map <- readOGR("SG_SIMD_2016_EDINBURGH.shp", stringsAsFactors = FALSE)
#check what object types we have
class(data)
class(Edinburgh_map)
#Check what are the column names of the dataframe, and of the spatial points dataframe?
names(data)
names(Edinburgh_map)
#check how many rows do each of the datasets contain?
nrow(data)
nrow(Edinburgh_map)
#check the coordinate system of the spatial polygons data frame
proj4string(Edinburgh_map)
#plot the spatial polygons data frame
plot(Edinburgh_map)
#convert the object into latitude and longitude for easier use with ggmap
Edinburgh_map <- spTransform(Edinburgh_map, CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs"))
#convert spatial polygon to dataframe including columns of spatial information
Edinburgh_fort <- fortify(Edinburgh_map, region= "DataZone")
#merge the new dataframe with the Edinburgh census data using their shared column
Edinburgh_fort <- merge(Edinburgh_fort, data, by.x="id", by.y="DataZone")
#create a plot of Income (Number of people who are income deprived)
ggplot(data=Edinburgh_fort, aes(x=long, y=lat, fill=IncNumDep, group=group)) +
scale_fill_viridis(name = "Income Deprivation")+
geom_polygon(colour="Gray")+
theme_void() +
theme(legend.position = "bottom") +
coord_equal()
#create a plot of Employment (Number of people who areemployment deprived)
ggplot(data=Edinburgh_fort, aes(x=long, y=lat, fill=EmpNumDep, group=group)) +
scale_fill_viridis(name = "Employment Deprivation")+
geom_polygon(colour="Black")+
theme_void() +
theme(legend.position = "bottom") +
coord_equal()
#create a plot of HouseNumOC (Number of people in households that are overcrowded )
ggplot(data=Edinburgh_fort, aes(x=long, y=lat, fill=HouseNumOC, group=group)) +
scale_fill_viridis(name = "Overcrowded Level")+
geom_polygon(colour="Black")+
theme_void() +
theme(legend.position = "bottom") +
coord_equal()
View(cluster_details)
#create a plot of HouseNumOC (Number of people in households that are overcrowded )
ggplot(data=Edinburgh_fort, aes(x=long, y=lat, fill=HouseNumOC, group=group)) +
scale_fill_viridis(name = "Overcrowded Level")+
geom_polygon(colour="Black")+
theme_void() +
theme(legend.position = "bottom") +
coord_equal()
#create a plot of EduNoQuals(Working age people with no qualifications)
ggplot(data=Edinburgh_fort, aes(x=long, y=lat, fill=EduNoQuals, group=group)) +
scale_fill_viridis(name = "Education Deprivation")+
geom_polygon(colour="Gray")+
theme_void() +
theme(legend.position = "bottom") +
coord_equal()
#choose the variables with which to train the SOM by subsetting the dataframe called data
data_train <- select(data, IncNumDep, EmpNumDep, HouseNumOC, EduNoQuals)
#convert to a matrix
data_train_matrix <- as.matrix(data_train)
#keep the column names of data_train as names in our new matrix
names(data_train_matrix) <- names(data_train)
#define the size and topology of the som grid
som_grid <- somgrid(xdim = 15, ydim=15, topo="hexagonal")
# Train the SOM model!
som_model <- som(data_train_matrix,
grid=som_grid,
rlen=500,
alpha=c(0.1,0.01),
keep.data = TRUE )
# Plot of the training progress - how the node distances have stabilised over time.
#mean distance to closes codebook vector during training
plot(som_model, type = "changes")
## load custom palette, created by Shane Lynn
source('coolBlueHotRed.R')
#counts within nodes
plot(som_model, type = "counts", main="Node Counts", palette.name=coolBlueHotRed)
#map quality
plot(som_model, type = "quality", main="Node Quality/Distance", palette.name=coolBlueHotRed)
#neighbour distances
plot(som_model, type="dist.neighbours", main = "SOM neighbour distances", palette.name=grey.colors)
#code spread
plot(som_model, type = "codes")
# Plot the heatmap for a variable at scaled / normalised values
var <- 1 #define the variable to plot
plot(som_model, type = "property", property = getCodes(som_model)[,var], main=colnames(getCodes(som_model))[var], palette.name=coolBlueHotRed)
var <- 2
plot(som_model, type = "property", property = getCodes(som_model)[,var], main=colnames(getCodes(som_model))[var], palette.name=coolBlueHotRed)
var <- 3
plot(som_model, type = "property", property = getCodes(som_model)[,var], main=colnames(getCodes(som_model))[var], palette.name=coolBlueHotRed)
var <- 4
plot(som_model, type = "property", property = getCodes(som_model)[,var], main=colnames(getCodes(som_model))[var], palette.name=coolBlueHotRed)
# show the WCSS metric for kmeans for different clustering sizes.
# Can be used as a "rough" indicator of the ideal number of clusters
mydata <- getCodes(som_model)
wss <- (nrow(mydata)-1)*sum(apply(mydata,2,var))
for (i in 2:15) wss[i] <- sum(kmeans(mydata,
centers=i)$withinss)
plot(1:15, wss, type="b", xlab="Number of Clusters",
ylab="Within groups sum of squares", main="Within cluster sum of squares (WCSS)")
# Form clusters on grid
## use hierarchical clustering to cluster the codebook vectors
som_cluster <- cutree(hclust(dist(getCodes(som_model))), 5)
# Colour palette definition
pretty_palette <- c("#D9D7F1", '#FFFDDE', '#2ca02c', '#E7FBBE', '#FFCBCB')
#show the same plot with the codes instead of just colours
plot(som_model, type="codes", bgcol = pretty_palette[som_cluster], main = "Clusters")
add.cluster.boundaries(som_model, som_cluster)
#create a label set for our SOM - a random subset of EDNAME
#extract the the names of areas in Edinburgh
geog_names <- Edinburgh_map@data$Intermedia
#most EDNAME values are repeated, so we'll remove duplicates, just to get an idea of the spread across Edinburgh
geog_names[duplicated(geog_names)] <- NA
#find the index of the names which are not NA
naset <- which(!is.na(geog_names))
#make all but 10 of the placenames in our data NA
naset <- sample(naset, length(naset)-10)
geog_names[naset] <- NA
# Replot our data with labels=geog_names
plot(som_model, type="mapping", bgcol = pretty_palette[som_cluster], main = "Clusters", labels=geog_names)
add.cluster.boundaries(som_model, som_cluster)
#create dataframe of the small area id and of the cluster unit
cluster_details <- data.frame(id=data$DataZone, cluster=som_cluster[som_model$unit.classif])
#we can just merge our cluster details onto the fortified spatial polygon dataframe we created earlier
mappoints <- merge(Edinburgh_fort, cluster_details, by="id")
pretty_palette1 <- c("#69779B", '#9692AF', '#ACDBDF', '#D7EAEA', '#41AAA8')
# Finally map the areas and colour by cluster
ggplot(data=mappoints, aes(x=long, y=lat, group=group, fill=factor(cluster))) +
geom_polygon(colour="black")  +
theme(legend.position = "bottom") +
coord_equal() +
scale_fill_manual(values = pretty_palette1)
